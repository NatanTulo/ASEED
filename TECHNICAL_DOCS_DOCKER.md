# ASEED - Dokumentacja Techniczna (Docker Edition)

## ğŸ³ PrzeglÄ…d architektury kontenerowej

ASEED to system analizy zamÃ³wieÅ„ e-commerce w czasie rzeczywistym zbudowany w architekturze mikroserwisÃ³w z wykorzystaniem kontenerÃ³w Docker.

```mermaid
graph TD
    A[Order Simulator Container] -->|JSON Messages| B[Kafka Container]
    B -->|Stream Processing| C[Spark Application Container]
    C -->|Analytics Results| D[Dashboard Container]
    E[Zookeeper Container] -->|Coordination| B
    F[Spark Master Container] -->|Job Management| C
    
    subgraph "Docker Network: aseed-network"
        A
        B
        C
        D
        E
        F
    end
    
    subgraph "External Access"
        G[User Browser] -->|:5005| D
        H[Spark UI] -->|:8080| F
        I[Kafka Client] -->|:9092| B
    end
```

## ğŸ”§ Komponenty kontenerowe

### 1. Zookeeper Container (`aseed-zookeeper`)
- **Image**: `confluentinc/cp-zookeeper:7.4.0`
- **Purpose**: Koordynacja i konfiguracja Kafka
- **Porty**: 2181
- **Health Check**: Sprawdzanie poÅ‚Ä…czenia na porcie 2181

### 2. Kafka Container (`aseed-kafka`)
- **Image**: `confluentinc/cp-kafka:7.4.0`
- **Purpose**: Message broker dla zamÃ³wieÅ„
- **Porty**: 9092 (external), 29092 (internal)
- **Dependencies**: Zookeeper
- **Health Check**: Sprawdzanie Kafka API

### 3. Spark Master Container (`aseed-spark-master`)
- **Image**: Custom `Dockerfile.spark` (based on bitnami/spark:3.5.0)
- **Purpose**: ZarzÄ…dzanie klastrem Spark
- **Porty**: 8080 (UI), 7077 (master)
- **Volumes**: `/opt/spark-apps`, `/opt/spark-logs`

### 4. Order Simulator Container (`aseed-order-simulator`)
- **Image**: Custom `Dockerfile.python` (Python 3.11)
- **Purpose**: Generowanie realistycznych zamÃ³wieÅ„ e-commerce
- **Command**: `python src/order_simulator.py`
- **Environment Variables**:
  - `KAFKA_BOOTSTRAP_SERVERS=kafka:29092`
  - `KAFKA_TOPIC=orders`
  - `MIN_ORDER_INTERVAL=3`
  - `MAX_ORDER_INTERVAL=8`

### 5. Data Analyzer Container (`aseed-data-analyzer`)
- **Image**: Custom `Dockerfile.spark-app` (Spark + Python)
- **Purpose**: Spark Structured Streaming analytics
- **Command**: `python src/data_analyzer.py`
- **Dependencies**: Kafka, Spark Master
- **Environment Variables**:
  - `KAFKA_BOOTSTRAP_SERVERS=kafka:29092`
  - `SPARK_MASTER_URL=spark://spark-master:7077`

### 6. Web Dashboard Container (`aseed-web-dashboard`)
- **Image**: Custom `Dockerfile.python`
- **Purpose**: Real-time web interface
- **Porty**: 5005
- **Command**: `python src/web_dashboard.py`
- **Environment Variables**:
  - `FLASK_HOST=0.0.0.0`
  - `FLASK_PORT=5005`

## ğŸ“¦ Docker Images

### Dockerfile.python
```dockerfile
FROM python:3.11-slim
# Installuje podstawowe zaleÅ¼noÅ›ci Python
# Kopiuje kod ÅºrÃ³dÅ‚owy z src/
# UÅ¼ywany przez: order-simulator, web-dashboard
```

### Dockerfile.spark
```dockerfile
FROM bitnami/spark:3.5.0
# Dodaje pakiety Python dla Spark
# Kopiuje aplikacje Spark
# UÅ¼ywany przez: spark-master
```

### Dockerfile.spark-app
```dockerfile
FROM bitnami/spark:3.5.0
# Instaluje wszystkie zaleÅ¼noÅ›ci dla aplikacji Spark
# Kopiuje kod analytics
# UÅ¼ywany przez: data-analyzer
```

## ğŸŒ SieÄ‡ Docker

### aseed-network (bridge)
- Wszystkie kontenery komunikujÄ… siÄ™ przez wewnÄ™trznÄ… sieÄ‡
- Service discovery przez nazwÄ™ kontenera
- Porty publiczne tylko dla dostÄ™pu zewnÄ™trznego

### Mapowanie portÃ³w
- `5005` â†’ Dashboard (web-dashboard:5005)
- `8080` â†’ Spark UI (spark-master:8080)
- `9092` â†’ Kafka (kafka:9092)
- `2181` â†’ Zookeeper (zookeeper:2181)

## ğŸ“Š PrzepÅ‚yw danych

### 1. Generowanie zamÃ³wieÅ„
```
Order Simulator â†’ Kafka Topic 'orders'
```

### 2. Przetwarzanie strumieniowe
```
Kafka â†’ Spark Structured Streaming â†’ Aggregacje
```

### 3. Prezentacja wynikÃ³w
```
Spark â†’ HTTP API â†’ Dashboard â†’ WebSocket â†’ Browser
```

## ğŸ” Health Checks

### Zookeeper
```bash
echo 'ruok' | nc localhost 2181
```

### Kafka
```bash
kafka-broker-api-versions --bootstrap-server localhost:9092
```

### Spark Master
```bash
curl -f http://localhost:8080
```

## ğŸ“‹ ZarzÄ…dzanie kontenerami

### Start systemu
```bash
./docker-aseed.sh start
```

### Monitoring
```bash
./docker-aseed.sh status
./docker-aseed.sh logs [service]
docker stats
```

### Debugging
```bash
docker exec -it aseed-web-dashboard /bin/bash
docker logs aseed-kafka
```

### Czyszczenie
```bash
./docker-aseed.sh cleanup
```

## ğŸ”§ Konfiguracja Å›rodowiska

### docker-compose.yml
- Definicja wszystkich serwisÃ³w
- Konfiguracja sieci i wolumenÃ³w
- Mapowanie portÃ³w i zmiennych Å›rodowiskowych

### Environment Variables
```yaml
# Order Simulator
KAFKA_BOOTSTRAP_SERVERS: "kafka:29092"
KAFKA_TOPIC: "orders"
MIN_ORDER_INTERVAL: "3"
MAX_ORDER_INTERVAL: "8"

# Data Analyzer  
SPARK_MASTER_URL: "spark://spark-master:7077"

# Dashboard
FLASK_HOST: "0.0.0.0"
FLASK_PORT: "5005"
```

## ğŸ“ˆ Monitoring i observability

### Logi kontenerÃ³w
```bash
docker logs aseed-order-simulator -f
docker logs aseed-data-analyzer -f
docker logs aseed-web-dashboard -f
```

### Metryki zasobÃ³w
```bash
docker stats
```

### Spark Monitoring
- **Spark Master UI**: http://localhost:8080
- **Application tracking**: Running/completed jobs
- **Resource usage**: Executors, memory, CPU

### Kafka Monitoring
```bash
# Lista topics
docker exec aseed-kafka kafka-topics --list --bootstrap-server localhost:9092

# Consumer groups
docker exec aseed-kafka kafka-consumer-groups --bootstrap-server localhost:9092 --list
```

## ğŸ”’ BezpieczeÅ„stwo

### SieÄ‡ izolowana
- Wszystkie kontenery w dedykowanej sieci `aseed-network`
- Komunikacja wewnÄ™trzna przez nazwy serwisÃ³w
- Porty publiczne tylko tam gdzie potrzebne

### Brak haseÅ‚/uwierzytelniania
- System rozwojowy bez uwierzytelniania
- Kafka i Spark w trybie insecure
- **Nie uÅ¼ywaÄ‡ w produkcji bez zabezpieczeÅ„**

## ğŸš€ Deployment

### Wymagania systemowe
- Docker 20.10+
- Docker Compose v2+  
- 4GB RAM
- 2GB miejsca na dysku

### Porty wymagane
- 5005 (Dashboard)
- 8080 (Spark UI)
- 9092 (Kafka)
- 2181 (Zookeeper)

### Ograniczenia
- Single-node deployment
- Brak persistence (dane w kontenerach)
- Brak load balancing
- Brak automatic scaling

---

**ğŸ³ Kompletna architektura mikroserwisÃ³w w Docker dla Å‚atwego wdroÅ¼enia i skalowania!**
