# Online Store Order A![Dashboard Preview](docs/dashboard-preview.png)

## ğŸ§ª Generator danych testowych

Do testowania wizualizacji dostÄ™pny jest generator przykÅ‚adowych zamÃ³wieÅ„:

```bash
# Generuj dane przez 2 minuty (6 zamÃ³wieÅ„/min)
./generate-test-data.sh

# Lub z custom parametrami
./generate-test-data.sh 5 10  # 5 minut, 10 zamÃ³wieÅ„/min
```

## ğŸ—ï¸ Architekturaysis

Projekt symulujÄ…cy sklep internetowy wysyÅ‚ajÄ…cy dane o zamÃ³wieniach przez Kafka, ktÃ³re sÄ… nastÄ™pnie analizowane przez Apache Spark w celu identyfikacji najlepiej sprzedajÄ…cych siÄ™ produktÃ³w.

## ï¿½ Web Dashboard

Projekt zawiera nowoczesny **interfejs webowy** do zarzÄ…dzania i monitorowania systemu:

```bash
./start-dashboard.sh
# OtwÃ³rz: http://localhost:5000
```

### FunkcjonalnoÅ›ci Dashboard:
- **ğŸ“Š Monitorowanie w czasie rzeczywistym** - CPU, RAM, Dysk, Load Average
- **ğŸ”§ ZarzÄ…dzanie serwisami** - Start/Stop wszystkich komponentÃ³w jednym klikniÄ™ciem  
- **ğŸ“ PodglÄ…d logÃ³w** - Real-time logi dla kaÅ¼dego serwisu
- **âš™ï¸ Konfiguracja** - Edycja wszystkich parametrÃ³w przez GUI
- **ğŸ’» Komendy systemowe** - Instalacja, sprawdzenie wymagaÅ„ przez interfejs
- **ğŸ“ˆ Wizualizacje danych** - Wykresy zamÃ³wieÅ„, top produkty, trendy kategorii
- **ğŸ§ª Generator danych testowych** - Symulacja ruchu dla testÃ³w dashboard

![Dashboard Preview](docs/dashboard-preview.png)

## ï¿½ğŸ—ï¸ Architektura

- **Apache Kafka + Zookeeper**: System kolejek wiadomoÅ›ci do strumieniowego przesyÅ‚ania zamÃ³wieÅ„
- **Apache Spark**: Silnik do analizy strumieniowej danych w trybie lokalnym
- **Order Simulator**: Generator symulowanych zamÃ³wieÅ„ (Python + Kafka Producer)
- **Data Analyzer**: Analizator real-time z metrykami top produktÃ³w (PySpark Structured Streaming)

## ğŸ“‹ Wymagania

- **4GB RAM** (minimum)
- **2GB wolnego miejsca na dysku**
- **Internet** (do pobierania Apache Kafka i Spark)

**Automatycznie instalowane:**
- **Java 11+**
- **Python 3** z pip
- **Apache Kafka 3.9.0**
- **Apache Spark 3.5.0**
- **Wymagane biblioteki Python** (pyspark, kafka-python, faker)

## ğŸš€ Szybki start

### Metoda 1: Web Dashboard (NOWA - ZALECANE!)
```bash
# Pobierz projekt
git clone https://github.com/NatanTulo/ASEED.git
cd ASEED

# Zainstaluj zaleÅ¼noÅ›ci
./install.sh

# Uruchom Web Dashboard
./start-dashboard.sh
```
**NastÄ™pnie otwÃ³rz:** http://localhost:5000

### Metoda 2: Interaktywne demo
```bash
# Pobierz projekt
git clone https://github.com/NatanTulo/ASEED.git
cd ASEED

# Uruchom interaktywny przewodnik
./demo.sh
```

### Metoda 3: Automatyczna instalacja (jedna komenda)
```bash
# Pobierz projekt
git clone https://github.com/NatanTulo/ASEED.git
cd ASEED

# Automatyczna instalacja + uruchomienie
./quickstart.sh
```

## ğŸ¯ Demo i testowanie

### ğŸŒ Web Dashboard z wizualizacjami (NOWOÅšÄ†!):
```bash
# Kompletna demonstracja z interaktywnymi wykresami
./demo-full.sh
```
**Funkcje dashboardu:**
- ğŸ“Š **Real-time analytics** - zamÃ³wienia i przychody na Å¼ywo
- ğŸ“ˆ **Wykresy trendÃ³w** - sprzedaÅ¼ w czasie (Chart.js)
- ğŸ¥§ **Wykres kategorii** - podziaÅ‚ produktÃ³w (doughnut chart)
- ğŸ† **TOP 10 produktÃ³w** - ranking najpopularniejszych
- ğŸ–¥ï¸ **System monitoring** - CPU, RAM, disk
- ğŸ›ï¸ **Sterowanie systemem** - start/stop usÅ‚ug z poziomu web

### Szybkie demo (konsola):
```bash
./demo.sh
```

### Krok po kroku:
```bash
# 1. Uruchom wszystkie usÅ‚ugi
./start.sh

# 2. Opcja A: Web Dashboard (zalecane)
./start-dashboard.sh       # DostÄ™pny: http://localhost:5000

# 2. Opcja B: Generuj przykÅ‚adowe zamÃ³wienia (konsola)
python3 src/order_simulator.py

# 3. W innym terminalu - analizuj dane
python3 src/data_analyzer.py
```

### Dane testowe dla wizualizacji:
```bash
# Podstawowe (2 min, 6 zamÃ³wieÅ„/min)
./generate-test-data.sh

# Intensywne (5 min, 20 zamÃ³wieÅ„/min)  
./generate-test-data.sh 5 20

# DÅ‚ugie (10 min, 2 zamÃ³wienia/min)
./generate-test-data.sh 10 2
```

## ğŸ“Š Co zobaczysz

### Logi analizy w czasie rzeczywistym
```bash
# Monitoruj wyniki analizy
./monitor.sh  # wybierz opcjÄ™ 1

# Lub bezpoÅ›rednio:
tail -f logs/data_analyzer.log
```

### PrzykÅ‚adowe wyniki
```
================================================================================
TOP PRODUKTY - Batch 123
================================================================================
 1. Electronics Smart Watch 15
    Kategoria: Electronics
    ZamÃ³wienia: 8, IloÅ›Ä‡: 15
    PrzychÃ³d: $1,247.85, Åšr. cena: $83.19
    Okno: 2025-01-15 14:30:00 - 2025-01-15 14:31:00

 2. Clothing Designer Jacket 7
    Kategoria: Clothing  
    ZamÃ³wienia: 6, IloÅ›Ä‡: 12
    PrzychÃ³d: $987.32, Åšr. cena: $164.55
```

### Status systemu
```bash
# SprawdÅº czy wszystkie komponenty dziaÅ‚ajÄ…
./monitor.sh  # wybierz opcjÄ™ 5
```

## âš™ï¸ Konfiguracja

Edytuj plik `.env` aby dostosowaÄ‡ parametry:

```env
# CzÄ™stotliwoÅ›Ä‡ generowania zamÃ³wieÅ„
ORDERS_PER_SECOND=2

# Liczba rÃ³Å¼nych produktÃ³w w katalogu
PRODUCT_COUNT=50

# Tryb Spark (local[*] uÅ¼ywa wszystkich rdzeni procesora)
SPARK_MASTER_URL=local[*]
```

## ğŸ› ï¸ Struktura projektu

```
ASEED/
â”œâ”€â”€ src/                          # Kod ÅºrÃ³dÅ‚owy aplikacji
â”‚   â”œâ”€â”€ order_simulator.py        # Generator zamÃ³wieÅ„
â”‚   â””â”€â”€ data_analyzer.py          # Analizator Spark
â”œâ”€â”€ logs/                         # Logi systemowe (tworzone automatycznie)
â”œâ”€â”€ pids/                         # Pliki PID procesÃ³w (tworzone automatycznie)
â”œâ”€â”€ venv/                         # Wirtualne Å›rodowisko Python (tworzone automatycznie)
â”œâ”€â”€ kafka_2.13-3.9.0/            # Apache Kafka (pobrane automatycznie)
â”œâ”€â”€ spark-3.5.0-bin-hadoop3/     # Apache Spark (pobrane automatycznie)
â”œâ”€â”€ .env                          # Konfiguracja Å›rodowiska
â”œâ”€â”€ requirements.txt              # Pakiety Python
â”œâ”€â”€ install.sh                    # Skrypt instalacji
â”œâ”€â”€ start.sh                      # Skrypt uruchomienia
â”œâ”€â”€ stop.sh                       # Skrypt zatrzymania
â”œâ”€â”€ monitor.sh                    # Skrypt monitorowania
â”œâ”€â”€ check-requirements.sh         # Sprawdzenie wymagaÅ„
â”œâ”€â”€ quickstart.sh                 # Szybki start
â”œâ”€â”€ demo.sh                       # Interaktywny przewodnik
â”œâ”€â”€ Makefile                      # Automatyzacja zadaÅ„
â””â”€â”€ TROUBLESHOOTING.md            # Przewodnik rozwiÄ…zywania problemÃ³w
```

## ğŸ”§ Dostosowania

### Modyfikacja produktÃ³w
Edytuj `src/order_simulator.py`:
- ZmieÅ„ kategorie w metodzie `_generate_products()`
- Dostosuj popularnoÅ›Ä‡ produktÃ³w w `_generate_product_weights()`

### Dodanie nowych analiz
Edytuj `src/data_analyzer.py`:
- Dodaj nowe agregacje w klasie `OrderAnalyzer`
- StwÃ³rz nowe okna czasowe dla rÃ³Å¼nych metryk

## ğŸ”§ Troubleshooting

### NajczÄ™stsze problemy:

**1. BÅ‚Ä…d "Port already in use"**
```bash
# SprawdÅº co uÅ¼ywa portÃ³w
netstat -tlnp | grep -E ':(2181|9092)'

# Zatrzymaj system i uruchom ponownie
./stop.sh
./start.sh
```

**2. BÅ‚Ä…d "Java not found"**
```bash
# Ubuntu/Debian
sudo apt install openjdk-11-jdk

# CentOS/RHEL/Fedora  
sudo dnf install java-11-openjdk-devel
```

**3. BÅ‚Ä…d "No space left on device"**
```bash
# WyczyÅ›Ä‡ stare logi
rm -rf logs/*

# SprawdÅº miejsce na dysku
df -h
```

**4. Spark nie moÅ¼e siÄ™ poÅ‚Ä…czyÄ‡ z Kafka**
```bash
# SprawdÅº czy Kafka dziaÅ‚a
./monitor.sh  # opcja 5

# SprawdÅº logi
tail -f logs/kafka.log
```

**5. Brak wynikÃ³w analizy**
```bash
# SprawdÅº czy symulator wysyÅ‚a dane
tail -f logs/order_simulator.log

# SprawdÅº topic Kafka
kafka_2.13-3.9.0/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic orders \
  --from-beginning
```

## ğŸ¯ Cele edukacyjne

Ten projekt demonstruje:
- âœ… **Kafka Producers/Consumers** - streaming danych w czasie rzeczywistym
- âœ… **Spark Structured Streaming** - analiza strumieniowa z agregatami okien czasowych  
- âœ… **Lokalne Å›rodowisko Big Data** - bez potrzeby klastra lub Docker
- âœ… **ETL Patterns** - extract, transform, load w Å›rodowisku strumieniowym
- âœ… **Real-time Analytics** - metryki biznesowe na Å¼ywo

## ğŸ“ˆ Rozszerzenia

### Proste rozszerzenia:
- Dodaj wiÄ™cej kategorii produktÃ³w
- Implementuj sezonowoÅ›Ä‡ w popularnoÅ›ci produktÃ³w  
- Dodaj analizÄ™ klientÃ³w (customer analytics)
- Zapisz wyniki do plikÃ³w CSV lub JSON

### Zaawansowane rozszerzenia:
- Integracja z bazÄ… danych (PostgreSQL/MySQL)
- Dashboard w Streamlit lub Flask
- Machine Learning dla predykcji trendÃ³w
- Integracja z systemami zewnÄ™trznymi przez REST API

## ğŸ§ª Testowanie

```bash
# SprawdÅº czy wszystkie komponenty dziaÅ‚ajÄ…
./check-requirements.sh

# Uruchom system na 5 minut i zatrzymaj
./start.sh
sleep 300
./stop.sh
```

---

**ğŸ’¡ WskazÃ³wka**: System uÅ¼ywa lokalnego trybu Spark (`local[*]`), wiÄ™c nie potrzebuje klastra ani Docker. Wszystko dziaÅ‚a na jednej maszynie!
