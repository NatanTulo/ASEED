# Spark application runner
FROM bitnami/spark:3.5.0

USER root

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install Python packages
RUN pip install --no-cache-dir \
    kafka-python==2.0.2 \
    pandas==2.1.3 \
    pyspark==3.5.0 \
    requests==2.31.0

# Copy application code
COPY src/ /opt/spark-apps/
RUN mkdir -p /opt/spark-logs

# Set permissions
RUN chown -R 1001:1001 /opt/spark-apps /opt/spark-logs

USER 1001

WORKDIR /opt/spark-apps

# Default command (overridden in docker-compose)
CMD ["python", "data_analyzer.py"]
